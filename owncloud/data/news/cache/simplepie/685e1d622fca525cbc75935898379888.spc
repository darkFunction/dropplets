a:4:{s:5:"child";a:1:{s:0:"";a:1:{s:3:"rss";a:1:{i:0;a:6:{s:4:"data";s:2:"

";s:7:"attribs";a:1:{s:0:"";a:1:{s:7:"version";s:3:"2.0";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:1:{s:7:"channel";a:1:{i:0;a:6:{s:4:"data";s:16:"















";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:10:"Sam Taylor";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:29:"http://notes.darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:16:"Online braindump";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"language";a:1:{i:0;a:5:{s:4:"data";s:5:"en-us";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 11 Apr 2014 14:11:30 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"item";a:10:{i:0;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:30:"Bitcoin IRC sentiment analysis";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:49:"http://notes.darkfunction.com/BitcoinIRCSentiment";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 26 Oct 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:49:"http://notes.darkfunction.com/BitcoinIRCSentiment";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:640:"<p>I wrote a Lua bot to sit and monitor the IRC channels listed <a href="https://en.bitcoin.it/wiki/IRC_channels">here</a> (minus the tickers) for uses of the &rsquo;sentiment words&rsquo; listed <a href="https://github.com/goncalopereira/twitter-moods/blob/master/moods">here</a>. Obviously this has no chance of giving meaningful results but it was a fun project.</p>

<p><a href="http://notes.darkfunction.com/coin/index.html">Click for the graph of <em>bitcoin price vs. bitcoin sentiment on IRC</em>.</a></p>

<p><a href="https://github.com/darkFunction/BitcoinIRCSentiment">https://github.com/darkFunction/BitcoinIRCSentiment</a></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:1;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:22:"Game Dev Diary: Part I";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:40:"http://notes.darkfunction.com/GameDevOne";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 26 Oct 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:40:"http://notes.darkfunction.com/GameDevOne";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:232:"<p>Work has started on a new game! I&rsquo;m using the <a href="http://getmoai.com/">Moai framework</a>.  Here&rsquo;s the latest screenshot:</p>

<p><img src="http://notes.darkfunction.com/images/game1.png" alt="Screenshot" /></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:2;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:23:"NSScotland 2013: Sunday";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:47:"http://notes.darkfunction.com/nsscotland_sunday";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sun, 20 Oct 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:47:"http://notes.darkfunction.com/nsscotland_sunday";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:11594:"<p>Notes from day two! </p>

<h3>How to Get Hired by Black Pixel (Matt Farrugia)</h3>

<p><img src="https://pbs.twimg.com/media/BXAro7rIEAACrUq.jpg" alt="Photo" /></p>

<p>This was really a talk about how to improve your skills, that you should be proactive in making a plan to improve yourself and identify areas of strength and weakness. I think Matt raises a good point that you should have a &rsquo;hard copy&rsquo; of your skillset and track what you know. </p>

<ul>
<li>Becoming a better developer

<ul>
<li><a href="http://www.imdb.com/title/tt1772925/">Love your work</a></li>
<li>Constantly look for areas of improvement</li>
<li>Write down your plan to improve

<ul>
<li><a href="http://i.imgur.com/WGEhRAe.png">Skills tree</a></li>
<li>Skills table of technologies - (None | Beginner | Intermediate | Expert)</li>
<li>Everyone will have a different plan.</li>
</ul></li>
<li>Software architecture

<ul>
<li>OO concepts</li>
<li>Scalability</li>
<li>Design patterns</li>
</ul></li>
<li>Debugging

<ul>
<li>Instrumentation</li>
<li>Scientific method</li>
<li>Code compression</li>
<li>Reductionism</li>
<li><strong>Stop guessing</strong>!</li>
</ul></li>
<li>Knowledge 

<ul>
<li>Experience</li>
<li>Speed</li>
<li>Quality</li>
<li>Completeness</li>
<li>Rework</li>
</ul></li>
<li>Aftermath

<ul>
<li>Simplicity</li>
<li>Test coverage</li>
<li>Technical debt</li>
<li>Code elegance</li>
<li>User experience</li>
<li>Support imapct</li>
<li>K.I.S.S.</li>
</ul></li>
</ul></li>
<li><a href="http://www.slideshare.net/evandrix/simple-made-easy">Simple Made Easy</a></li>
<li>The Practice of Learning

<ul>
<li>Concrete experience</li>
<li>Reflective observation</li>
<li>Abstract conceptualisation</li>
<li>Active experimentation</li>
</ul></li>
</ul>

<h3>Core Audio (Gordon Murrison)</h3>

<p>Gordon Murrison is a co-author of <a href="http://www.smoovie.com/">Smoovie</a>.  This presentation showed the use of CoreAudio to build a metronome, and manipulate sound (applying effects to a generated sine wave). Kicked off with a little bit of history of music technology.</p>

<ul>
<li>History

<ul>
<li>MIDI

<ul>
<li>Simple protocol, key pressed, key released, press strength</li>
</ul></li>
<li>Digital audio

<ul>
<li>Mono is about 80KB/s, stereo is 160KB/s</li>
<li>PCI cards</li>
</ul></li>
<li>CoreAudio </li>
<li>Generally, use NSSound and AVAudioPlayer - high level, simple, fast, and relatively advanced so you shoulnd&rsquo;t need to dig down further.</li>
</ul></li>
<li>Building a metronome

<ul>
<li>Can&rsquo;t rely on NSTimer accuracy under CPU load.

<ul>
<li>Use Audio File Services to work directly with queues for accurate timing.</li>
</ul></li>
</ul></li>
<li>Audio Units

<ul>
<li>Plugins which process audio</li>
<li>DSP processes input- properties are set before running, parameters affect sound during run.</li>
<li>Unit has about 10ms to process data</li>
<li>Audio Unit Graphs

<ul>
<li>Nodes represent units</li>
<li>Sine wave generator, chained units, eg reverb, delay</li>
</ul></li>
</ul></li>
</ul>

<h3>Virtually Understanding Memory (Jamie Montgomerie)</h3>

<p>Technical overview of memory management on OS X and iOS.  Very fast paced and very informative, feel as though I learned the most from this talk although perhaps not much that I can immediately put into practice. Made virtual memory a bit less mysterious and a lot more interesting.</p>

<ul>
<li>Virtual memory on iOS- iOS does have a virtual memory system very similar to OS X.</li>
<li>Application memory.

<ul>
<li>64 bit address space can address more memory than could physically exist.</li>
<li>An app doesn&rsquo;t get access to all the space immediately.</li>
<li>Space is split into chunks (<em>pages</em>) 4k big, managed by OS kernel.</li>
<li>A set of continuous pages is called a memory &ldquo;region". </li>
<li>Application must use kernel APIs to request memory access.</li>
<li>Use vmmap to look at the virtual memory map for a running application. Works for simulator. (eg, vmmap vim -resident -dirty)

<ul>
<li>Columns: Type, Range, Size, Permissions, Maximum Permisssions, Share Mode (PRIvate, Copy On Write, SHared, ALIased)</li>
<li>All pages have no neccessary associaton with real physical memory.</li>
</ul></li>
<li>Pages backed by real RAM are called &ldquo;resident".</li>
<li>Pages that are in RAM but not on disk are dirty (eg, malloc).</li>
<li>File backed regions are read lazily.</li>
<li>A page fault occurs when reading memory which is not resident, or when a Copy On Write region is modified.</li>
<li>Instruments only tracks memory allocated through alloc, it doesn&rsquo;t track virtual memory.

<ul>
<li>For example, CALayer objects are just handles but exist much larger in real RAM.  </li>
<li>Some system frameworks bypass the kernel APIs and work directly with the virtual memory system, eg, NS/UIImage.</li>
<li>New instruments &ldquo;all anonymous VM&rdquo; can show virtual memory use (though not with any granularity).</li>
</ul></li>
</ul></li>
<li>Framework code, resources and memory-mapped files(?) can be shared between applications and only loaded into RAM once.</li>
<li>Allocated regions from malloc are not really allocated until they are used. Very efficient system.</li>
<li>The system accounts for pages as ACTIVE | INACTIVE | FREE.</li>
<li>Under pressure:

<ul>
<li>Removes clean cached files and purgable writable regions.</li>
<li>Writes dirty sections of shared files to disk.</li>
</ul></li>
<li>Using the VM system for yourself

<ul>
<li>Allocating anonymous memory

<ul>
<li>Just use malloc</li>
</ul></li>
<li>Memory mapping a file (great for large, sparse data)

<ul>
<li>NSData    </li>
<li>BSD mmap C API (sys/mmap.h)</li>
</ul></li>
<li>Sharing the memory between processes (POSIX semaphores)</li>
</ul></li>
<li>When not to use the VM system directly:

<ul>
<li>Dealing with files smaller than 4k page size, just malloc.</li>
<li>Mapping can fragment memory space.</li>
<li>Surprisingly easy to run out of address space in 32 bit.</li>
<li>XPC or distributed objects might be a better inter-process method of sharing memory.</li>
</ul></li>
<li>Purgable regions

<ul>
<li>Special kind of memory, not file backed, discardable</li>
<li>Good for data that is fast and easy to recreate</li>
<li>NSCache is based on this

<ul>
<li>NSPurgableData / NSPurgableContent</li>
<li>Can use these objects in NSCache, works well.</li>
</ul></li>
</ul></li>
<li>iOS virtual memory is nearly identical to OS X, the only thing missing is dynamic paging on non-disk-backed data.</li>
<li>Look for RPRVT column in <em>top</em> to see a program&rsquo;s virtual memory usage. </li>
<li>More info:

<ul>
<li>Apple docs 

<ul>
<li>Memory usage performance guidelines</li>
</ul></li>
<li><em>man vmmap</em></li>
</ul></li>
</ul>

<h3>Accessibility (Matt Gemmell)</h3>

<p><img src="https://pbs.twimg.com/media/BXBgMDCIcAAVsfl.png" alt="Photo" /></p>

<ul>
<li>Haptic feedback will be a big win in the future for accessibility but we are not there yet.</li>
<li>How to use VoiceOver mode on the iPhone:

<ul>
<li>Select, navigate, activate</li>
<li>Keyboard- slide finger, other finger to select</li>
<li>Search

<ul>
<li>Can actually search entire screen, not just the content, so blind users actually have more power here.</li>
</ul></li>
<li>Label 

<ul>
<li>Can actually relabel items manually and implement your own accessibility ID&rsquo;s <em>(temporary solution for automation?)</em></li>
</ul></li>
<li>Curtain 

<ul>
<li>Tap three times with three fingers to deactivate screen</li>
</ul></li>
<li>Scrub cancel

<ul>
<li>Z-shaped gesture with two fingers to cancel/go back.</li>
</ul></li>
<li>Battery lasts longer when not powering the screen.</li>
<li>Magic tap

<ul>
<li>A two-finger double-tap that performs the most-intended action.</li>
</ul></li>
<li>The rotor - changes interaction mode

<ul>
<li>For example, change navigation mode to only navigate links / words / characters.</li>
</ul></li>
</ul></li>
<li>Why should you care?

<ul>
<li>These devices are a lifeline for people with disabilities.</li>
<li>They are tools of inclusion and independence.</li>
<li>285 million people worldwide are visually impaired (90% are in the developing world).</li>
</ul></li>
<li>One simple API, UIAccessibility.

<ul>
<li><em>Label</em> is a brief name, ie, &ldquo;Play".</li>
<li><em>Hint</em> is what the item does, ie, &ldquo;Plays the current song".</li>
</ul></li>
<li>Acccessibility inspector in the simulator is a bit shit, should test on device.</li>
<li>Can make VoiceOver say something at specific times, read content.</li>
<li>Skip animations if in VoiceOver mode?</li>
<li>Don&rsquo;t rely on gestures- VoiceOver will own them.

<ul>
<li><strong>Potential issue with slide-to-profile?</strong></li>
</ul></li>
<li>"Label your bloody icons"</li>
<li>"Blind people won&rsquo;t use my app&rdquo; - Blind people <em>will</em> use your app.</li>
<li>What are blind users doing with smartphones?

<ul>
<li>Colour identification

<ul>
<li>Matching clothes</li>
</ul></li>
<li>Is it charged?</li>
<li>Did i leave the lights on?</li>
<li>Games

<ul>
<li>Board / card / word / puzzle</li>
</ul></li>
</ul></li>
<li>Trust the technology, it is simple, quick to implement and really matters.</li>
</ul>

<h3>Seeing The Bigger Picture (Simon Wolf)</h3>

<p>Didn&rsquo;t take notes. A talk about the general usage of dual screens and catering for them in Mac applications. </p>

<h4>Included:</h4>

<ul>
<li>Brief history of Airplay</li>
<li>Coding for multiple screens and airplay mirroring

<ul>
<li><em>Look</em> (at start) and <em>listen</em> for screens becoming active/inactive.</li>
</ul></li>
<li>Dealing with overscan </li>
</ul>

<p>(... no more notes)</p>

<h3>Architectural Patterns for Wetware Systems (Graham Lee)</h3>

<p><img src="https://pbs.twimg.com/media/BXB7z8SIEAA9zgc.jpg" alt="Photo" /></p>

<p>A talk not related to programming but a look at how we interact with each other, problem solve and patterns of human behaviour stemming from mental schemata.  Very entertaining talk but a little meta, the notes don&rsquo;t really detail much but Graham Lee touched on a lot of interesting history about physics, beliefs, and psychology.  Fun end to the conference.</p>

<h4>What was talked about</h4>

<ul>
<li>Interacting with others.</li>
<li>(Using wave particle duality vs. Einstein example), should model reality, not try to make reality fit your view.</li>
<li>If user finds a way to do something other than the most optimal way, they will stick to it anyway.</li>
<li>Internal schemata:

<ul>
<li>Behaviours</li>
<li>Beliefs</li>
<li>Attitudes</li>
<li>Values</li>
<li>False beliefs based on coincidence</li>
</ul></li>
<li>Predjudice

<ul>
<li>"Easier to think that people who are different to me are all similar"</li>
</ul></li>
<li>Cognitive dissonance (internal story to reinforce false beliefs)

<ul>
<li>The more a metaphor breaks down, the more effort to maintain the belief.</li>
</ul></li>
<li>Attentional blindness, we filter out a lot. Example: motorists not seeing cyclists.</li>
<li>Phonological loop. Sound eats into conciousness after about 2 seconds.</li>
<li>Bystander apathy.</li>
<li>Focus narrows as you become busier.</li>
<li>Romantic / Classic quality (Zen and the Art of Motorcycle Maintenance)

<ul>
<li>Misunderstand or misunderestimate what the other quality is about.</li>
<li>Non-appreciation of underlying code.</li>
<li>Non-appreciation of end product.</li>
<li>Apple accounts for both- bottom up (classic) and top down (romantic).</li>
</ul></li>
<li>Bias blind spot.</li>
</ul>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:3;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:25:"NSScotland 2013: Saturday";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:49:"http://notes.darkfunction.com/nsscotland_saturday";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 19 Oct 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:49:"http://notes.darkfunction.com/nsscotland_saturday";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:10022:"<p>Notes from day one!</p>

<h3>Crazy and Focused (Daniel Steinberg)</h3>

<p><img src="https://pbs.twimg.com/media/BW7kgV6IcAAqbFz.jpg" alt="Photo" /></p>

<p>Steinberg delivered a motivating presentation encouraging developers to focus in on the core elements of our apps, and how we should clearly and specifically identify our users. </p>

<h4>Key points</h4>

<ul>
<li>If you ask your users what they want, they will ask for everything.  Stay focused on your core features.</li>
<li>Apps can suck in subtle ways (for example, not using the email keyboard for email input).  Most of your work will never be noticed, but if you don&rsquo;t add the polish, people will notice.</li>
<li>The &ldquo;app definition statement&rdquo; - For What, Whom and Why.  Brainstorm ideas and whittle down to key elements.</li>
<li>If you try to reach everyone, you will reach noone. Be really specific about who you are targeting and try to connect with them.  The iPhone is way more personal than a computer or laptop. People carry your app with them and they touch it directly. They often use headphones and not speakers- you are &ldquo;literally the voice inside their head".  This allows you to really narrow down your features. &ldquo;Talk to one person, touch many".</li>
<li>Don&rsquo;t try to change the world.  Try to change the world for one person.</li>
<li>Keep it simple.</li>
<li>"There are a thousand no&rsquo;s for every yes". You may not use all of your work, you keep the good stuff and discard the rest.</li>
<li>You don&rsquo;t have infinite time- working on one thing often means abandoning another.</li>
</ul>

<h3>Making Friends With Documents (Neil Inglis)</h3>

<p>Didn&rsquo;t really take notes on this one. Demo of sample code for reading and writing to NSDocuments/UIDocuments.</p>

<h4>In short</h4>

<ul>
<li>TextEdit source is a good reference.</li>
<li>Don&rsquo;t use NSCoder / NSArchiver - use an intermediary format.</li>
<li>Advantages to UIDocument:

<ul>
<li>Asynchronous read and write.</li>
<li>iCloud.</li>
<li>Autosave. NSUndoManager automatically created.</li>
<li>Safe saving.</li>
</ul></li>
<li>Gotchas: Enums can be different on iOS / OSX, eg, NSTextAlignment.</li>
<li>Document is composed of multiple files, eg, images etc. Users sees a document but it is actually a filesystem. Use NSFileWrapper, or custom format and Zip it.</li>
</ul>

<h3>iBeacons, Bluetooth LE and Arduinos (Matthew Robinson)</h3>

<p>A presentation on how to setup iBeacons. Demonstrated a pyrometer transmitting live temperature updates to an iPhone and OSX. Essentially the technology is promising, but still flaky, and the amount of code required to begin using iBeacons is trivial. Spoke to Matthew about whether an application can simultaneously act as Central and Peripheral, which he thought wouldn&rsquo;t be a problem since the OS monitors for multiple applications at the same time so it&rsquo;s not  a limitation with the hardware. He thinks the range can be around 25 metres, but it just depends on the device power. iPads transmit with greater power than iPhones.</p>

<h4>Key points</h4>

<ul>
<li>BluetoothLE is:

<ul>
<li>Low Energy.</li>
<li>Low bandwidth.</li>
</ul></li>
<li>Find BLE services with BLEExplorer app.</li>
<li>Client aka &ldquo;Central", Server aka &ldquo;Peripheral".  iOS can act as both.</li>
<li>Can homebrew external hardware for iPhones now, which is exciting.</li>
<li>All services are identified by UUIDs.</li>
<li>Services have Characteristics, eg, pyrometer service has &rsquo;temperature&rsquo; and &rsquo;rate of change&rsquo; 

<ul>
<li>Readable / writable / notify on change.</li>
</ul></li>
<li>Use CoreBluetooth (CB...) api&rsquo;s. 

<ul>
<li>1) Scan for peripherals and receive callback.</li>
<li>2) Ask for services and receive callback. </li>
<li>3) Ask for characteristics and receive callback.</li>
<li>4) Register for updates.</li>
</ul></li>
<li>iBeacons

<ul>
<li>Supported in CoreLocation, don&rsquo;t need to worry about CoreBluetooth.</li>
<li>Hardware information still under NDA? </li>
<li>The ibeacons can <em>maybe</em> run upto 2 years on a watch battery(!)</li>
<li>Peripheral sends advertisement data:

<ul>
<li><strong>Proximity UUID</strong> (unique to group of iBeacons, for example, those owned by your company).</li>
<li><strong>Major</strong> - a 16 bit integer - use for anything - maybe unique id for store or something.</li>
<li><strong>Minor</strong> - another 16 bit integer - again, anything.</li>
<li><strong>Measured power</strong> - received signal strength measured at one metre from the iBeacon, not precise.</li>
</ul></li>
<li>Create CLBeaconRegion, monitor it instead of CLRegion.</li>
<li>Start monitoring region, will wake app even if not running(!).</li>
<li>CLProximity: UNKNOWN, IMMEDIATE, NEAR, FAR. 

<ul>
<li>If you have multiple beacons found, the nearest is the first object.</li>
<li>UNKNOWN is sorted before IMMEDIATE(!)</li>
</ul></li>
<li>Maybe not quite ready for prime-time.</li>
<li>Temperamental, don&rsquo;t always get notifications or can take minutes to work.</li>
</ul></li>
</ul>

<h3>Core Data in Motion</h3>

<p><strong>JUST ADDED: <a href="http://www.slideshare.net/wndxlori/core-data-in-motion">Presentation slides</a></strong></p>

<p>Mostly a demo of RubyMotion code for handling large datasets through CoreData. Actually didn&rsquo;t know about RubyMotion before the demo so it was quite hard to follow. RubyMotion allows you to write iOS applications in Ruby, being able to interface with the Apple frameworks but leverage the power of Ruby on top.</p>

<h4>Some points</h4>

<ul>
<li>Ray Wenderlich&rsquo;s tutorials and sample code (&rsquo;Failed Bank&rsquo;, &rsquo;Locations&rsquo;) are excellent starting points for this kind of project.</li>
<li>RubyMotion magic and Xcode magic hide quite a lot, although it takes surprisingly little code to manage huge and complex datasets manually.

<ul>
<li>Write models (entities) in code.</li>
<li>Write relationships in code.</li>
<li>Define your entities, first.</li>
<li>Lazily define entities attributes and relationships.</li>
</ul></li>
</ul>

<h3>Testing iOS Applications (Steven Baker)</h3>

<p>This was a high-level overview of testing strategies for iOS.  Pointed out that nowadays we have options when it comes to testing iOS.</p>

<p>I spoke to Steven after the presentation to ask about any advantages to using Kiwi, I was curious about whether it was just really the same thing wrapped in different language semantics. He said that it was, and that if you are already using OCUnit and you are happy with it, that there is no reason to switch.  He personally prefers and uses xUnit despite being the author of RSpec (which Kiwi is a clone of). I mentioned awkward mocking in OCMock, especially regarding value passing, and he said that&rsquo;s a side effect of the extreme difficulty of writing mocking frameworks, but that Kiwi is probably better in that respect.</p>

<h4>Key points</h4>

<ul>
<li>Big proponent of TDD, said he is unable to develop anything without it. </li>
<li>TDD is a design activty, results in more decoupled software. Your code is reusable by definition since the test and the application are both using it.</li>
<li>xUnit (eg, OCUnit JUnit)

<ul>
<li>One approach to describing tests.</li>
<li>Same style across languages.</li>
<li>Can use it to learn new languages! Start with a failing test case, and continue from there.</li>
</ul></li>
<li>BDD

<ul>
<li>Merges TDD and DDD.</li>
<li>Aims to more accurately reflect intent.</li>
<li>Descibes behaviours over testing code.</li>
</ul></li>
<li>Acceptance testing

<ul>
<li>"I will know that the software is complete when...".</li>
<li>Comprehensive regression test.</li>
<li>Start a new feature with an acceptance test.</li>
</ul></li>
<li>Mocks and stubs

<ul>
<li>Managing dependencies.</li>
<li>Improves isolation.</li>
<li>Ensures expected behaviours.</li>
</ul></li>
<li>Automation

<ul>
<li>Cucumber 

<ul>
<li>Provides Gherkin natural language.</li>
<li>Given, And, When, Then, natural language backed by functions.</li>
</ul></li>
<li>Frank (this is what Steven Baker uses and recommends)

<ul>
<li>Cucumber for iOS apps.

<ul>
<li>Most Given/Then/When functions are pre-written.</li>
</ul></li>
</ul></li>
<li>Zucchini (the one to watch)

<ul>
<li>CoffeeScript view descriptions, not Gherkin natural language.</li>
<li>Can test against screenshots.</li>
</ul></li>
<li>Calabash (Steven doesn&rsquo;t use this personally but has friends that recommend it)

<ul>
<li>Cucumber for iOS and Android.</li>
<li>"Only option really for cross platform".</li>
</ul></li>
<li>Instruments

<ul>
<li>JS to control iOS app.</li>
<li>Horrible readability.</li>
</ul></li>
</ul></li>
<li>Unit Testing Tools

<ul>
<li>OCUnit

<ul>
<li>Built in.</li>
<li>Very mature.</li>
<li>Recommended.</li>
</ul></li>
<li>Kiwi

<ul>
<li>BDD Framework.</li>
<li>RSpec clone.</li>
<li>No Xcode integration.</li>
<li>Thinks it is less readable with all the syntactic sugar in Objective-C.</li>
</ul></li>
</ul></li>
</ul>

<h3>20 Years of Indie Mac Development (James Thomson)</h3>

<p><img src="https://pbs.twimg.com/media/BXDBkubIIAI4s29.png" alt="Intro" /></p>

<p>James Thompson gave an account of his career developing for Apple Macs, working on DragThing and the MacOS dock, and rewriting PCalc many times for new platforms.  Some good anecdotes including one about Steve Jobs wanting to get rid of him because he was a remote developer working in Ireland, and so he had to have an office in San Francisco and pretend to be located there. Interesting talk and a lighthearted end to day one.</p>

<h4>Lessons learned</h4>

<ul>
<li>Comment your code well, might still be in use in 20 years.</li>
<li>Get code ready for day one, eg, AppStore, iOS7. Huge spike in profits.</li>
<li>Think about code reuse.</li>
<li>Support from other developers is invaluable.</li>
<li>Use some of the profits to fund the next development.</li>
<li>Don&rsquo;t write games. (Why not?)</li>
</ul>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:4;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:23:"Visualising Objective-C";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:36:"http://notes.darkfunction.com/DFGrok";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 04 Sep 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:36:"http://notes.darkfunction.com/DFGrok";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:2708:"<p>As developers we spend a lot of time sketching out class relationships and program flow in notebooks or on whiteboards, as a shared point of reference when communicating ideas or as a personal memory aid.  A few months ago I discovered a handy online generator called <a href="http://yuml.me">yUML</a>.  It describes itself as being for &ldquo;light, back-of-napkin style UML usage", and provides a simple syntax that allows you to quickly type out class relationships which it then renders into basic, prettified UML.  It&rsquo;s ideal for everyday use where formal UML is time-consuming to produce and unfriendly on the eye.</p>

<p>I wanted to create a tool that would allow a developer to quickly see the relationships between a limited set of classes.  A lot of automated UML tools tend to dump the whole project into an incomprehensible diagrammatic bolognese which is of no use to anyone. I also didn&rsquo;t want it to include too much information in the UML- if it shows everything then you really might as well be looking at the code.  So, I present <a href="https://github.com/darkFunction/DFGrok">DFGrok, a command line application for auto-generating yUML from Objective-C implementation files</a>.</p>

<p><a href="https://github.com/darkFunction/DFGrok">DFGrok</a> only maps the classes you input, and automatically pulls in direct relatives.  Importantly it ignores anything that isn&rsquo;t a connection between the specified classes.  It will show immediate superclasses, stong and weak ownership, and interface inheritance (but not interfaces which do not connect two key classes).  It even detects one-to-many ownership by looking at which objects get stored in member <em>NSArrays</em> and <em>NSDictionaries</em>.  A cool feature is the use of colour to represent class types to reduce clutter.  For example, you can specify that UIViewController descendants are green, both removing the need to show the UIViewController class, and allowing better visual distinction between elements.</p>

<p><a href="https://github.com/darkFunction/DFGrok">DFGrok</a> is not intended as a tool for producing documentation, or for digging down into details.  Its strengths are in what it <em>doesn&rsquo;t</em> do.  If you have an unfamiliar feature it can just help you to get a high level overview of the key relationships to be aware of.</p>

<p><em>Note: currently only projects which have member variables exclusively as <strong>properties</strong> are supported!</em></p>

<h5>Screenshot (key below):</h5>

<p><img src="http://notes.darkfunction.com/images/yuml2.png" alt="Example output" /></p>

<h5>Key:</h5>

<p><img src="http://notes.darkfunction.com/images/yumlkey.png" alt="Key" /></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:5;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:25:"Jalapeno, one month later";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:54:"http://notes.darkfunction.com/jalapeno_one_month_later";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 30 Aug 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:54:"http://notes.darkfunction.com/jalapeno_one_month_later";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:797:"<p>Just a little status update for the Jalapeno that has been chugging along nicely for just over a month now.  I replaced the obnoxious fan with a quieter one, and about 2 weeks ago I flashed the firmware, putting the speed up to about 7.5GH/s.  This speed increase coincided with the huge difficulty rise earlier in the month, so the graph looks more even than it would if it were still running at stock speed.  Below is my graph from Slush&rsquo;s pool, and a screenshot from CGMiner.  The spike to zero that you can see is me knocking the plug out and not noticing for a day ;)</p>

<p>To date it has paid out 2.50 BTC, which at the current conversion rate is £206.05</p>

<p><img src="images/miningGraph.png" alt="pool graph" />
<img src="images/mining7.png" alt="cgminer screenshot" /></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:6;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:42:"Bitforce Jalapeno + Raspberry Pi + cgminer";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:38:"http://notes.darkfunction.com/jalapeno";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Thu, 25 Jul 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:38:"http://notes.darkfunction.com/jalapeno";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:720:"<p>My BFL Jalapeno finally arrived.  It&rsquo;s a cute little box but the fan is really whirring away, so I ordered <a href="http://www.amazon.co.uk/gp/product/B009LELXQG/ref=oh_details_o00_s00_i00?ie=UTF8&amp;psc=1">a replacement</a>.  It&rsquo;s sitting in the living room plugged into a Pi which is also acting as a backup file server.  I&rsquo;m monitoring cgminer on this box through my VPS which has a tmux screen pane devoted to it, so that I can keep an eye on it without having to login all the time.  It&rsquo;s steady around 42°C and 5.3Gh/s.</p>

<p><img src="images/cgminer.png" alt="cgminer screenshot" /></p>

<p><a href="http://stinkydigit.darkfunction.com/miner.php">Web monitor for this miner</a></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:7;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:20:"Idea: Digital Jotter";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:49:"http://notes.darkfunction.com/Digital-jotter-idea";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 19 Jun 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:49:"http://notes.darkfunction.com/Digital-jotter-idea";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:654:"<p>It would be cool to have some kind of functionality on a blog which allowed you to show all revisions of a post as if it were written down on paper and revised by scribbling out words or paragraphs.  This way you would be able to see all the bad work as well as the good, next to each other in a kind of natural way.  This wouldn&rsquo;t be very suitable for most things, but what I had in mind was language learning.  If I want to keep a blog in French and correct spelling or grammatical mistakes as I learn them, I would want to see some kind of visual history of my errors- it seems more useful than a perfectly presented wall of French text.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:8;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:18:"Dropplets + BTSync";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:46:"http://notes.darkfunction.com/Dropplets-BTSync";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Thu, 30 May 2013 00:00:00 +0100";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:46:"http://notes.darkfunction.com/Dropplets-BTSync";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:444:"<p>Just installed Dropplets, love the clean layout and simplicity.  Since the content of the Dropplets site is just a directory with <a href="http://daringfireball.net/projects/markdown/">markdown</a> textfiles, I thought it would be cool to BTSync this folder. Now all I have to do to publish a post is make a new textfile on any machine in the same synced folder, and it will be published as soon as there&rsquo;s an internet connection!</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:9;a:6:{s:4:"data";s:7:"






";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:6:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:14:"Lucid Dreaming";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:44:"http://notes.darkfunction.com/Lucid-Dreaming";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 15 Jan 2013 00:00:00 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:5:{s:4:"data";s:28:" Sam
 - sam@darkfunction.com";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:44:"http://notes.darkfunction.com/Lucid-Dreaming";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:7156:"<p>Lucid dreaming is the conscious realisation that you are dreaming, becoming fully aware and &#8216;awake&#8217; while still asleep. Most people have had one at some time or another. The concept garnered some popularity around the release of <em><a href="http://www.imdb.com/title/tt1375666/" title="Inception">Inception</a></em> and was a main theme in the film <em><a href="http://www.imdb.com/title/tt0243017/" title="Waking Life">Waking Life</a></em>.</p>

<p>Usually when you tell someone you are interested in lucid dreaming, you might as well have said that you dowse for spirit crystals under the light of a full moon.  But unlike astrology, homeopathy, and good indie music, this phenomenon has been empirically demonstrated to exist. With enough practice, it can be induced at will.</p>

<p>For a long time, the validity of lucid dream reports was considered untestable as there was no way to communicate to the outside world from the dream state. Lucidity was explained away as a brief awakening or false memory, sometimes theorised to be impossible or absurd. Then in 1975, psychologist Keith Hearne realised that since the full-body paralysis which occurs during sleep does not affect the eye musculature, it might be possible for a dreamer to signal the onset of lucidity with deliberate ocular motion. A subject would be required to make an agreed-upon sequence of left-right eye movements after entering <a href="http://en.wikipedia.org/wiki/Rapid_eye_movement_sleep" title="Rapid Eye Movement">REM sleep</a>, which could then be observed by a collaborator with an <a href="http://en.wikipedia.org/wiki/Electrooculography">EOG machine</a>. He confirmed this on the 12th of April 1975 with the <strong>first ever recorded signal from within a dream</strong>.</p>

<p><img src="http://darkfunction.com/sam/wp-content/uploads/2013/01/moon.jpg" alt="Some rights reserved by NASA Goddard Photo and Video" title="Some rights reserved by NASA Goddard Photo and Video" /></p>

<p>This opened up a broad new avenues of research for oneirology (the scientific study of dreams). Around the same time, researcher Stephen LaBerge duplicated Hearne&#8217;s results independently, which became the first peer reviewed publication on the technique. Through the eighties, LaBerge experimented and developed methods to achieve lucidity at will. In 1995 he published the seminal book <a href="http://www.amazon.co.uk/Exploring-World-Dreams-Stephen-LaBerge/dp/034537410X/ref=sr_1_1?ie=UTF8&amp;qid=1358087787&amp;sr=8-1" title="Exploring the World of Lucid Dreaming">Exploring the World of Lucid Dreaming</a>, which summarises a decade of his research- a sort of <em>How To</em> for aspiring lucid dreamers.</p>

<p><figure></p>

<blockquote>
  <p>&#8220;Further practice and refinements led to a method whereby I could reliably induce lucid dreams. With this new method, I had as many as four lucid dreams in one night, and as many as twenty-six in one month.&#8221;
  <figcaption>&#8211; Stephen Laberge, Exploring the World of Lucid Dreaming (p.73)</figcaption>
  </figure></p>
</blockquote>

<p>So while you are desperately trying to build a mozzarella rope bridge to escape a swarm of tiny pensioners, LaBerge is probably <del>walking</del> flying around his dreamscape like Neo in the matrix, punching helicopters out of the sky with flaming plasma fists. Or cackling madly in an underground bone palace crafted from the charred remains of his enemies (who knows?).</p>

<h2>Alright, sounds cool. How do I do it?</h2>

<p>The idea is pretty straight-forward. In order to realise you&#8217;re dreaming, you need to be in the habit of questioning reality often enough in waking life for it to become an automatic unconscious action. These &#8216;state tests&#8217; can make use of certain oddities of dreams- examples such as light switches not working, the appearance of <em>dreamsigns</em> (more on that in a second), or text appearing jumbled up. Or you can simply do a quick mental exercise: am I awake? Is there anything strange about my situation? How did I get here? To practice, LaBerge recommends setting yourself targets each day of doing a reality check on pre-defined triggers. For example:</p>

<h3>Sunday</h3>

<ul>
<li>The next time I see a pet or animal</li>
<li>The next time I look at my face in a mirror</li>
<li>The next time I turn on a light</li>
<li>The next time I bite the head off a pigeon</li>
</ul>

<h3>Monday</h3>

<ul>
<li>The next time I write anything down</li>
<li>The next time I hear someone say my name</li>
<li>The next time I drink something</li>
<li>The next time I reload my crossbow</li>
</ul>

<p>If you are unable to remember to perform them in your day-to-day life then it is unlikely you will remember to do them your dreams either. Different things work for different people. You may decide you want to do a reality check every time you pass through a door, or on the hour when your watch beeps.</p>

<p>Another important skill is <em>recall</em>. It helps to write your dreams in a journal as soon as you wake up (otherwise they will quickly be forgotten). Before you can make a serious attempt at becoming lucid you should be able to remember at least one dream every night. Recall is important because it allows you to become familiar with your dreams and learn to recognise commonly occurring features, people or places &#8211; <em>dreamsigns</em> &#8211; that can prompt you to state test.</p>

<p>With enough practice, motivation, and positive self-reinforcement before bed, anyone should be able to become lucid.</p>

<p>There are lots of detailed articles on the Web about the principles developed by LaBerge and others, which I won&#8217;t cover here. But there is another technique used by advanced practitioners, or &#8216;oneironauts&#8217;, worth touching on&#8230;</p>

<h2>Wake Induced Lucid Dreams (W.I.L.D.)</h2>

<p>WILD&#8217;s are best attempted a couple of hours before you would normally wake up, when your REM periods are the longest and you are relaxed. The premise is to wake up, then drift back into a sleepy hypnagogic state while keeping your body absolutely still and purposeful awareness at the forefront of your mind. This might involve counting- &#8220;<em>One, I&#8217;m dreaming, two, I&#8217;m dreaming&#8230;</em>&#8220;, or simply watching the hypnogogic imagery from the detached perspective of a passive observer. At some point your body will enter sleep paralysis and you may hear a loud buzzing noise, feel vibrations, or see patterns of colours in your vision. Shortly after, when the dream emerges fully, you will have retained an unbroken stream of consciousness and lucidity. Of course this is all easier said than done and requires a degree of perseverance and motivation.</p>

<h2>More info</h2>

<p>Reddit is always a useful source of information so I&#8217;d recommend having a look through <a href="http://www.reddit.com/r/luciddreaming">http://www.reddit.com/r/luciddreaming</a> for further reading.</p>

<p>If you&#8217;re looking for a (very informal) podcast on the subject, I enjoy <a href="http://get-lucid.net/" title="Get Lucid!">Get Lucid</a>.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}}}}}}}}}}}s:4:"type";i:128;s:7:"headers";a:8:{s:4:"date";s:29:"Fri, 11 Apr 2014 13:11:30 GMT";s:6:"server";s:22:"Apache/2.2.16 (Debian)";s:12:"x-powered-by";s:21:"PHP/5.3.3-7+squeeze19";s:4:"vary";s:15:"Accept-Encoding";s:16:"content-encoding";s:4:"gzip";s:14:"content-length";s:5:"14844";s:10:"connection";s:5:"close";s:12:"content-type";s:8:"text/xml";}s:5:"build";s:14:"20130718145142";}